HTML code
```
<html>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Recognized Alphabets</title>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
</head>
<body>
<form method="POST">
    <video id="video" autoplay class="w-100" style="width: 90%;aspect-ratio:1;"></video>
    <br />
    <div class="btn-group-vertical" role="group" aria-label="Vertical radio toggle button group">
      <input type="radio" class="btn-check" name="vbtn-radio" id="vbtn-radio1" style="display: none;" autocomplete="off"
        onchange="check(this.id)">
      <label class="btn btn-outline-danger" for="vbtn-radio1">Start Camera</label>
      <input type="radio" class="btn-check" name="vbtn-radio" id="vbtn-radio2" style="display: none;" autocomplete="off"
        checked onchange="check(this.id)">
      <label class="btn btn-outline-danger" for="vbtn-radio2">Stop Camera</label>
      <input type="button" class="btn btn-info" onclick="switchCamera()" value="Switch Camera">
    </div>
    <div id="recognized-alphabet"></div>

</form>
<script>
  let videoStream;
  let currentCamera = 'environment'; // 'environment' for rear, 'user' for front

  function check(r) {
    if (r === "vbtn-radio1") {
      startCamera();
    }
    if (r === "vbtn-radio2") {
      stopCamera();
    }
  }
  async function switchCamera() {
    if (document.getElementById('video').srcObject != null) {
      stopCamera();
      currentCamera = currentCamera === 'environment' ? 'user' : 'environment';
      startCamera();
    }
  }
  async function startCamera() {
    try {
      videoStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: currentCamera } });
      document.getElementById('video').srcObject = videoStream;
      setInterval(captureFrame, 1000);
    } catch (error) {
      console.error('Error accessing camera:', error);
    }
  }

  const canvas = document.createElement('canvas');
  const context = canvas.getContext('2d');




  // Capture frames
  function captureFrame() {
    context.drawImage(video, 0, 0, canvas.width, canvas.height);
    canvas.toBlob(sendDataToFlask, 'image/png'); // Convert to Blob
  }

  function sendDataToFlask(blobData) {
    var xhr = new XMLHttpRequest();
    xhr.open('POST', '/process_video_frames', true);
    xhr.setRequestHeader('Content-Type', 'application/octet-stream');
    xhr.onload = function () {
      if (xhr.status === 200) {
        console.log('Data sent successfully');
      } else {
        console.error('Error sending data to Flask:', xhr.statusText);
      }
    };
    xhr.onerror = function () {
      console.error('Network error while sending data to Flask');
    };
    xhr.send(blobData);
  }

  function stopCamera() {
    if (videoStream) {
      videoStream.getTracks().forEach(track => track.stop());
      document.getElementById('video').srcObject = null;
    }
  }
</script>
<script>
  $(document).ready(function() {
      // Start the process of getting recognized alphabets
      getRecognizedAlphabet();
  });

  function getRecognizedAlphabet() {
      // Send a POST request to the server to get the recognized alphabet
      $.ajax({
          url: '/process_video_frames',
          type: 'POST',
          success: function(data) {
              // Update the content of the recognized-alphabet element with the recognized alphabet
              $('#recognized-alphabet').text(data);
          },
          error: function(xhr, status, error) {
              // Handle errors, e.g., display an error message
              console.error('Error:', error);
          },
          complete: function() {
              // Schedule the next request after 1 second
              setTimeout(getRecognizedAlphabet, 1000);
          }
      });
  }
</script>
<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
  integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
  integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
 integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


</body>
</html>

```







flask app
```
from flask import Flask, render_template, redirect, url_for, session, request, flash, get_flashed_messages
from flask import Response,jsonify
import cv2, sys, numpy as np, os, base64, joblib
from io import BytesIO
from PIL import Image,UnidentifiedImageError
import mediapipe as mp
import pickle
import time

app = Flask(__name__)
@app.after_request
def add_header(response):
    response.cache_control.no_store = True
    return response

@app.route("/", methods=['GET', 'POST'])
def login():

    return render_template('index.html')


@app.route('/process_video_frames', methods=['POST'])
def process_video_frames():
    global recognized_alphabets,recognized_alphabet
    try:
        image_data_bytes = request.data  # Assuming request is properly defined

        # Convert bytes to numpy array
        nparr = np.frombuffer(image_data_bytes, np.uint8)

        # Decode numpy array into an image
        image_cv2 = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        # Check if the image is empty
        if image_cv2 is not None and not np.all(image_cv2 == 0):
            # Convert cv2 image to RGB  
            image_rgb = cv2.cvtColor(image_cv2, cv2.COLOR_BGR2RGB)
            image_pil = Image.fromarray(image_rgb)
        
        model_dict = pickle.load(open('./model.p', 'rb'))
        model = model_dict['model']

        mp_hands = mp.solutions.hands
        mp_drawing = mp.solutions.drawing_utils
        mp_drawing_styles = mp.solutions.drawing_styles

        hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.5)

        labels_dict = {
            0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: ' ',
            6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M',
            12: 'N', 13: 'O', 14: 'P', 15: 'Q', 16: 'R', 17: 'S',
            18: 'T', 19: 'U', 20: 'V', 21: 'W', 22: 'X', 23: 'Y'
        }

        # Initialize variables
        gesture_start_time = None
        recognized_alphabets = []
        alphabet_counts = {label: 0 for label in labels_dict.values()}
        results = hands.process(image_rgb)

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                x_ = []
                y_ = []
                data_aux = []

                mp_drawing.draw_landmarks(
                    image_rgb,  # image to draw
                    hand_landmarks,  # model output
                    mp_hands.HAND_CONNECTIONS,  # hand connections
                    mp_drawing_styles.get_default_hand_landmarks_style(),
                    mp_drawing_styles.get_default_hand_connections_style())

                for i in range(len(hand_landmarks.landmark)):
                    x = hand_landmarks.landmark[i].x
                    y = hand_landmarks.landmark[i].y

                    x_.append(x)
                    y_.append(y)

                for i in range(len(hand_landmarks.landmark)):
                    x = hand_landmarks.landmark[i].x
                    y = hand_landmarks.landmark[i].y
                    data_aux.append(x - min(x_))
                    data_aux.append(y - min(y_))

                # Recognize alphabet
                prediction = model.predict([np.asarray(data_aux)])
                recognized_alphabet = labels_dict[int(prediction[0])]
                print(recognized_alphabet)

                recognized_alphabets.append(recognized_alphabet)



                alphabet_counts[recognized_alphabet] += 1

                # Start gesture recognition timer
                if gesture_start_time is None:
                    gesture_start_time = time.time()

            # Check if 2 seconds have passed
            if gesture_start_time is not None and time.time() - gesture_start_time >= 2:
                # Find most frequent recognized alphabet
                most_common_alphabet = max(alphabet_counts, key=alphabet_counts.get)
                if alphabet_counts[most_common_alphabet] >= 1:
                    recognized_alphabets.append(most_common_alphabet)
                    word = ''.join(recognized_alphabets)
                    print("Recognized word:", word)
                
                # Reset variables
                alphabet_counts = {label: 0 for label in labels_dict.values()}
                gesture_start_time = None
        
        # Send the recognized alphabet immediately as a response to the client
        return recognized_alphabet

    except Exception as e:
        print("Error:", e)
        return 'Failure'
if __name__ == "__main__":
    app.run(debug=True)

```